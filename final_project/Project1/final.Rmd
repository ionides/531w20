---
title: "Time Series Analysis on US Tourist Demand after COVID-19"
author: "Chuwen Li"
output:
  html_document:
    theme: flatly
    toc: yes
---

\newcommand\prob{\mathbb{P}}
\newcommand\E{\mathbb{E}}
\newcommand\var{\mathrm{Var}}
\newcommand\cov{\mathrm{Cov}}

-----------

```{r , echo=FALSE,warning=FALSE,message=FALSE}
# this block loads R packages that may be needed for the analysis.
library(dplyr)
library(ggplot2)
library(forecast)
library(astsa)
library(tseries)
theme_set(theme_bw())
library(reshape2)
library(magrittr)
library(pomp)
```


# 1 Introduction

After the breakout of Coronavirus (COVID-19) in Wuhan, China in December 2019, strict quarantine policies are implemented in China. US then released travel restrictions to and from China in January, 2020 to stop the spread of COVID-19. Quantifying the impact of COVID-19 on the U.S. tourism demand is the interest of this report. This report is a continue work on the impact analysis of US tourist demand using POMP and GARCH modeling and compare it to the Seasonal Autoregressive Integrated Moving Average (SARIMA) Model. 

The data of overseas non-resident arrivals to the U.S. was extracted from the U.S. Government website: National Travel & Tourism Office. The data spans from January, 2003 to March, 2020 and its measurement includes all countries except Canada and Mexico. Notice the data set updated on the February and March overseas non-resident arrivals

Section 2 is the data overview and recap of midterm project. Section 3 includes: Pomp modeling and its likelihood estimation.

# 2 SARIMA Model

## 2.1 Summary Results 

The trend plot is shown below:

```{r read_data, echo=FALSE, warning=FALSE,message=FALSE, fig.width=9, fig.height=4.5}
set.seed(1234)
tour <- read.csv("US_OverseaVistits.csv")
tour$Time <- as.Date(tour$Time, format = "%Y-%m-%d")
tour_m <- tour[1:(nrow(tour)-3),]

Visits <- tour_m$Arrivals
Visits2 <- tour$Arrivals
Visits_ts <- ts(Visits, start=2003, frequency=12)

plot.ts(Visits_ts,type="l", main="US Overseas Visits Series", xlab="Year",ylab="US Overseas Visits", sub="Figure 1")
```

the SARIMA model for non-stationary monthly data $(p, d, q)\times (P, D, Q)_12$ is defined as $$\phi(B)\Phi(B^{12})((1-B)^d(1-B)^{12})^D Y_n-\mu)=\psi(B)\Psi(B^{12})\epsilon_n,$$ where $\phi(B)$ and $\Phi(B)$ are polynomials in $B$ of order $p$ and $q$, $psi(B)$ and$\Psi(B)$ polynomials in $B^{12}$ of order $P$ and $Q$, $Y_t$ is the observation at time $t$, $\mu=E[(1-B)^d(1-B)^{12})^D]$ is the mean of the differenced process, and $\epsilon_t$ is the white noise with mean $0$ and constant variance $\sigma^2.$

The SARIMA model on the updated data is SARIMA$(3, 0, 4)\times (1, 1, 1)_{12}$, the summary results is shown as follows

```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.width=9, fig.height=4.5}
auto.arima(log(Visits_ts))
```


## 2.2 Diagnostic Plots and Prediction

```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.width=9, fig.height=4.5}
vfit <- lm(Visits~time(Visits))
detour_m <- resid(vfit)
detour_m <- ts(detour_m, start=2003, frequency=12)

best_fit <- arima(detour_m,order=c(3,0,4),seasonal=list(order=c(1,1,1),period=12))
par(mfrow=c(1,2))
resi_acf <- acf(resid(best_fit),plot = FALSE)
plot(resi_acf, xlab = "Lag (in Year)", main = "ACF of Residual")
qqnorm(resid(best_fit), main="Q-Q plot")
qqline(resid(best_fit))

```

We can see the diagnostic plots shows the SARIMA model is reasonable for the data set. The log-likelihood of it is 323.5.

```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.width=9, fig.height=4.5}
Visits_ts2 <- ts(Visits2, start=2003, frequency=12)
fore <- sarima.for(Visits_ts, 3, 3,0,4, 1,1,1,12, plot=F)
plot(cbind(Visits_ts, fore$pred), plot.type = "single", type = "n", 
  xlim = c(2003, 2020),
  xlab = "Year", ylab="Overseas Non-resident Arrivals",
  main = "SARIMA(3,0,4)(1,1,1)_{12}")
lines(Visits_ts2, type = "p")
lines(Visits_ts2)
lines(fore$pred, col = "blue", type = "p")
lines(fore$pred, col = "blue")
lines(fore$pred + 1.96 * fore$se, lty = 2, col = "red")
lines(fore$pred - 1.96 * fore$se, lty = 2, col = "red")
```

The prediction of SARIMA$(3, 0, 4)\times (1, 1, 1)_{12}$ for January, February and March, 2020 are the red points on the plot. As we can see the oversea non-resident arrivals for March is far below expectation.  

# 3 POMP Modeling

## 3.1 Geometric Brownian Motionl

Rprocess is based on geometric brownian motion (GRM) model of which the logarithm of randomly varying quantity a Brownian motion. It has two state variables: $N$ and $\epsilon$ and three parameters: $\mu$ (drift), $\sigma$. and $\delta$ (volatility) (Brewer et al. 2016). The differential equation is 

$$dN=\mu Ndt+\delta N \epsilon \sqrt{dt}$$
$$d log(N)=(\mu-\frac{\delta^2}{2}) dt+\delta \epsilon \sqrt{dt}$$
where $N$ is the arrivals in each month and $\epsilon$ is a random draw from $N(0,\sigma)$.
Solving the above equation, we can get 
$$N_{t+\Delta t}=N_t \exp((\mu-\frac{\delta^2}{2}) \Delta t+\delta \epsilon \sqrt{\Delta t})$$,
$$N_{t+1}=N_t \exp((\mu-\frac{\delta^2}{2}) \frac{1}{n}+ \frac{\delta}{\sqrt{n}} \epsilon)$$,
where $n$ represents the number of months in a year.

## 3.2 Building a POMP Model 

We first to take log to detrend data for pomp modeling.
```{r,echo=FALSE, warning=FALSE,message=FALSE, fig.width=9, fig.height=4.5}
set.seed(2022)
tour$Arrivals <- log(tour$Arrivals)
#parus<-pomp(tour_m[,2:3],times="Year",t0=2002)
#plot(parus)
```

We first define variables in the pomp object and the initial value of $N$ and $\epsilon=0$ are set to be 10 and rpois(1). Rmeasure is defined as random draw from a normal distribution with mean 0 and variance $N$. 

```{r, warning=FALSE,message=FALSE, fig.width=9, fig.height=4.5}
pop_statenames = c("N", "e")
pop_paramnames = c("mu","delta","sigma")

stochStep <- Csnippet("e = rnorm(0,sigma);
                  N = N*exp((mu-delta*delta/2)/12+delta/sqrt(12)*e);")

initlz <- Csnippet("N=10;e=rpois(1);")
dmeas <- Csnippet("lik = dnorm(Arrivals,0,N,give_log);")
rmeas <- Csnippet("Arrivals = rnorm(0,N);")
```


```{r, warning=FALSE,message=FALSE, fig.width=9, fig.height=4.5}
pomp(data = tour[,1:2],
     times="Month",
     t0=0,
     rprocess=discrete_time(step.fun=stochStep,delta.t=1),
     rinit=initlz,
     rmeasure = rmeas, dmeasure = dmeas,
     statenames=pop_statenames,
     paramnames=pop_paramnames,
     partrans=parameter_trans(
      log=c("mu","sigma"),
      logit="delta")
     ) -> pop_pomp
```


## 3.3 Log-likehood Slice and Surface
Next, we would like to investigate the likelihood surface of our model by construct a geometric surface and see how the log-likelihood changes with parameters.
```{r,echo=FALSE, warning=FALSE,message=FALSE, fig.width=9, fig.height=4.5}
run_level <- 2
pop_Np <-switch(run_level,100, 500, 1000)
pop_Nmif <- switch(run_level,10, 100, 200)
pop_Neval <- switch(run_level,4,  10,  20)
pop_Nglobal <-switch(run_level,10, 20, 100)
pop_Nlocal <- switch(run_level,10, 20, 20)

library(doParallel)

cluster_cores <- as.numeric(Sys.getenv('SLURM_NTASKS_PER_NODE'))
CLUSTER <- !is.na(cluster_cores)
if(CLUSTER) registerDoParallel(cluster_cores) else registerDoParallel()

library(doRNG)
registerDoRNG(1929385)

```

```{r,echo=FALSE, warning=FALSE, message=FALSE, fig.width=9, fig.height=4.5}
sliceDesign(
  c(N.0=10,e.0=0.3,mu=0.5,delta=0.8,sigma=0.1),
  mu=rep(seq(from=0,to=1,length=50),each=3),
  sigma=rep(seq(from=0,to=1,length=50),each=3),
  delta=rep(seq(from=0.5,to=1.5,length=50),each=3)) -> p

foreach(theta=iter(p,"row"), .packages='pomp',
         .combine=rbind,.inorder=FALSE) %dopar% {
           pfilter(pop_pomp,params=unlist(theta),Np=1000) -> pf 
           theta$loglik <- logLik(pf)
           theta} -> p

foreach (v=c("mu","sigma","delta")) %do% 
{
  x <- subset(p,slice==v)
  plot(x[[v]],x$loglik,xlab=v,ylab="loglik")
}
```

From log-likelihood plots, we can see log-likelihood is maximized at around $\mu=0.4$ along $\mu$ direction, $\delta=1$ along $\delta$ direction, and $\sigma=0.3$ along $\sigma$ direction.


```{r,echo=FALSE, warning=FALSE,message=FALSE, fig.width=9, fig.height=4.5}
pf <- replicate(10,pfilter(pop_pomp,Np=pop_Np,params=c(N.0=10,e.0=0.3,mu=0.5,delta=0.8,sigma=0.1)))
ll <- sapply(pf,logLik); ll
logmeanexp(ll,se=TRUE)
```

The Particle Filter gives an unbiased Monte Carlo estimate of the log-likelihood. Given 1000 particles, the model, and the parameters, we get an estimate of log-likelihood -884.80 with standard error of 0.57.

## 3.4 Maximizing the Likelihood Using the Particle Filter

### 3.4.1 Local Search

We need to build new pomp object before conducting a local maximum likelihood search around previously identified MLE.
```{r,echo=FALSE, warning=FALSE,message=FALSE, fig.width=9, fig.height=4.5}
pop_rw.sd <- 0.02
pop_cooling.fraction.50 <- 0.5

pomp(
  data=tour[,1:2],
  times="Month",
  t0=0,
  rprocess=euler(step.fun=stochStep,delta.t=1),
  rmeasure=rmeas,
  dmeasure=dmeas,
  statenames=pop_statenames,
  paramnames=pop_paramnames,
  obsnames = "Arrivals",
  partrans=parameter_trans(
      log=c("mu","sigma"),
      logit="delta"),
  rinit=initlz) -> pop_pomp2


stew(file=sprintf("pop_local-%d.rda",run_level),{
  t_local <- system.time({
    mifs_local <- foreach(i=1:pop_Nglobal,
      .packages='pomp', .combine=c) %dopar% mif2(
        pop_pomp2,
        params=c(N.0=10,e.0=0.3,mu=0.4,delta=1,sigma=0.3),
        Np=pop_Np, 
        Nmif=pop_Nmif,
        cooling.fraction.50=pop_cooling.fraction.50,
        transform=TRUE, 
        rw.sd=rw.sd(
          mu=pop_rw.sd,
          delta=pop_rw.sd,
          sigma = pop_rw.sd)
      )
  })
})

stew(file=sprintf("pop_lik_local-%d.rda",run_level),{
  t_local_eval <- system.time({
    liks_local <- foreach(i=1:pop_Nlocal,.packages='pomp',.combine=rbind) %dopar% {
      evals <- replicate(pop_Neval,
              logLik(pfilter(pop_pomp2,params=coef(mifs_local[[i]]),Np=pop_Np)))
      logmeanexp(evals, se=TRUE)
    }
  })
})

pop_results_local <- data.frame(logLik=liks_local[,1],logLik_se=liks_local[,2],t(sapply(mifs_local,coef)))
summary(pop_results_local$logLik,digits=5)

pairs(~logLik+mu+delta+sigma,data=subset(pop_results_local,logLik>max(logLik)-50))
```

The maximum loh-likelihood result from local search is -856.2 and the scatter plots shows the likelihood surface in the neighborhood of given point estimates.


### 3.4.3 Global Search

Next, we would like to conduct a global search of log-likelihood. The parameter box is given below:

```{r, warning=FALSE,message=FALSE, fig.width=9, fig.height=4.5}
pop_box <- rbind(mu=c(0, 1),
                 delta=c(0,3),
                 sigma=c(0,3))
```


```{r,echo=FALSE, warning=FALSE,eval =FALSE,fig.width=9, fig.height=4.5}
pop_fixed_params <- c(N.0=14.67,e.0=0.3)
stew(file=sprintf("box_eval-%d.rda",run_level),{
  t_global <- system.time({
    mifs_global <- foreach(i=1:pop_Nlocal,.packages='pomp', .combine=c) %dopar% 
      mif2(
        pop_pomp.2,
        params=c(apply(pop_box,1,function(x)runif(1,x[1],x[2])),
                 pop_fixed_params),
        Np=pop_Np, 
        Nmif=pop_Nmif, 
        cooling.fraction.50=pop_cooling.fraction.50,
        transform=TRUE, 
        rw.sd=rw.sd(
          mu=pop_rw.sd,
          delta=pop_rw.sd,
          sigma = pop_rw.sd
        )
      )
  })
})

stew(file=sprintf("lik_global_eval-%d.rda", run_level),{
  t_global_eval <- system.time({
    liks_global <- foreach(i=1:pop_Nglobal,.packages='pomp',
      .combine=rbind)%dopar% {
      evals <- replicate(pop_Neval,
      logLik(pfilter(pop_pomp,params=coef(mifs_global[[i]]),
                     Np=pop_Np)))
      logmeanexp(evals, se=TRUE)
    }
  })
})
results_global <- data.frame(logLik=liks_global[,1], logLik_se =
                               liks_global[,2],t(sapply(mifs_global,coef)));
summary(results_global$logLik, digits = 5);
```


```{r,echo=FALSE, warning=FALSE,message=FALSE,fig.width=9, fig.height=4.5}
plot(mifs_local)
```

Both local search and global search give similar max log-likelihood. From the POMP diagnostics plot, we can see overall parameters converges but there is some Monte Carlo variation. $\hat \mu$, $\hat \delta$, and $\hat \sigma$ converge to their maximum-likelihood estimates.


# 4 Conclusion

 In this project, For the US overseas visits data from 2003 to 2020, SARIMA $(3, 0, 4)\times (1, 1, 1)_{12}$ gives quite good prediction and proves a large abnormal decrease of oversea visits after 2020. Especially for March, the number of visits below estimation more than 2 standard deviation. Although SARIMA model can capture almost all validation of data with clear trend and seasonality, it is quite hard to interpret. Pomp modeling, on the other hand, is easier to explain. Despite it under performs SARIMA model in terms of log-likelihood, it is more adaptable to data with high volatility.

# 5 References

[1] Data: https://travel.trade.gov/view/m-2017-I-001/index.asp

[2] Coronavirus: https://www.cdc.gov/coronavirus/2019-ncov/about/transmission.html

[3] Avdiu, K. Brownian Motion & Geometric Brownian Motion. Retrieved April 26, 2018, from http://homepage.univie.ac.at/kujtim.avdiu/dateien/BrownianMotion.pdf.

[4] Previous Project: https://ionides.github.io/531w18/final_project/3/final.html#geometric-brownian-motion

[5] Lecture notes.







