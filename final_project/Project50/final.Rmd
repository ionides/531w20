---
title: "STATS 531 Final Project: Candy Production Index(CPI)"
output: 
  html_document:
    theme: flatly
    highlight: tango
    includes:
    toc: true
    number_sections: true
    toc_depth: 2
    toc_float:
      collapsed: false
      smooth_scroll: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Background Introduction  

This final project is the further anlysis of the midterm project. Candy Production Index(CPI) dataset is from FRED economic research and includes monthly candy production index from 1972 Jananury to 2020 March. Both projects make analysis of the candy production index dataset, while the focuses are different. Midterm project focused on the seasonal effect of candy production index and mainly used ARIMA and SARIMA model to fit. While in final project, the main point is to fit different model on the CPI and select the best one with larger log likelihood. As the focus changed, the data used will be the demeaned seasonal adjusted one instead of raw data.  

## Exploratory Data Analysis (EDA)  

From the summary below, we can see that the CPI range from 55.99 to 127.5 on the level of 2012 index as 100 and the dataset includes 579 data points.

```{r data,echo=FALSE,warning=FALSE,message=FALSE,cache=TRUE}
ipi <- read.csv('IPG3113S.csv') 
ipi$DATE <- strptime(ipi$DATE,"%Y-%m-%d")
ipi$year <- as.numeric(format(ipi$DATE,format = '%Y'))
ipi$month <- as.numeric(format(ipi$DATE,format = '%m'))
ipi$time <- ipi$year + ipi$month/12
head(ipi,n=5L)
summary(ipi$IPG3113S)
hist(ipi$IPG3113S,xlab = 'CPI',main = 'Histogram of CPI')
```

## Detrend & data transform

Plotting raw IPI against time and the acf of the data, we can see a clear trend with large auto correlation. This means data transformtion is needed. After data is demeaned, the plot is quite more stationary and the data is nearly uncorrelated.  

```{r eda,echo=FALSE,warning=FALSE,message=FALSE,cache=TRUE}
par(mfrow=c(2,1))
candy=ipi$IPG3113S
time=ipi$time
candy_loess <- loess(candy~time,span = 0.5)
plot(candy~time,xlab='Date',ylab='CPI',type='l',main='Plot of CPI')
lines(candy_loess$x,candy_loess$fitted,type = 'l',col='red')
acf(candy)
lcandy= diff(log(candy))
dmcandy = lcandy-mean(lcandy)
plot(dmcandy,xlab='Date',ylab='CPI',type='l',main='Plot of CPI(demeaned)')
acf(dmcandy)
```

From the spectrum plot, we can see that the red dashed line shows it reached its peak at a frequency value of 0.33 which means it may has a seasonality of a period of 3 months.  

```{r spect,echo=FALSE,warning=FALSE,message=FALSE,cache=TRUE}
dmcan_spe <- spectrum(dmcandy,spans=c(3,5,3),main = 'Smoothed Periodogram')
abline(v=dmcan_spe$freq[which.max(dmcan_spe$spec)],col='red',lty='dotted')
```

In decomposition plot, we can see the candy_low variable, representing the trend and cycles waved inquite small ranges and the noise plot is similar with the original demeaned plot. This indicates the data process is successfully detrended and what left was mostly the noise part.  

```{r trendnoisecycles,echo=FALSE,warning=FALSE,message=FALSE,cache=TRUE}
adtime = time[1:578]
lcandy_low <-ts(loess(dmcandy~adtime,span=0.4)$fitted,start = 1972,frequency = 3)
lcandy_high <-ts(lcandy-loess(dmcandy~adtime,span=0.1)$fitted,start = 1972,frequency = 3)
lcandy_cycles <- lcandy - lcandy_high - lcandy_low
plot(ts.union(lcandy,lcandy_low,lcandy_high,lcandy_cycles),main='Decomposition of candy production as trend + noise +cycles')
```

# Midterm part(ARMA&SARIMA model)  

In midterm project, we fitted ARIMA and SARIMA model on the CPI data and the output of simulation shows it worked well. While in the final project, we will start with the ARIMA & SARIMA model selected by midterm analysis and then refit with greater aic value and larger log likelihood.  

## Fit ARIMA&SARIMA selected by midterm project

ARIMA & SARIMA selected by midterm with no seasonal adjusted dan do not remove the trend.  
The ARIMA model selected is ARIMA(0,1,1) and the sarima model selected is $SARIMA(4,0,3)\times(0,1,1)_{12}$.  

```{r arima,echo=FALSE,warning=FALSE,message=FALSE,cache=TRUE}
arima(dmcandy,order=c(0,1,1))
arima(dmcandy,order=c(4,0,3),seasonal = list(order=c(0,1,1),period=12))
```

## Fit new ARIMA & SARIMA model  

Fristly, We fit the ARIMA model with different AR and MA parameter values and get a table of AIC value. In the table, we can see that all the value is less than -2234.1 which is ARIMA(0,1,1) aic value shown above. 

```{r newarima,echo=FALSE,warning=FALSE,message=FALSE,cache=TRUE}
aic_table <-function(data,P,Q){
  table <-matrix(NA,(P+1),(Q+1))
  for(p in 0:P){
    for(q in 0:Q){
      table[p+1,q+1] <- arima(data,order =c(p,0,q))$aic
    }
  }
  dimnames(table) <- list(paste("AR",0:P,sep=""),paste("MA",0:Q,sep=""))
  table
}
l_aic_table <-aic_table(dmcandy,4,5)
l_aic_table
```

Then we fit SARIMA model with new seasonal period as 3 months. And comparing $SARIMA(0,0,3)\times(0,1,1)_{3}$ with ARIMA(0,1,1) selected by ARIMA aic value.  

```{r newsarima,echo=FALSE,warning=FALSE,message=FALSE,cache=TRUE}
saic_table <-function(data,P,Q){
  table <-matrix(NA,(P+1),(Q+1))
  for(p in 0:P){
    for(q in 0:Q){
      table[p+1,q+1] <- arima(data,order =c(p,0,q),seasonal = list(order=c(0,1,1),period=3))$aic
    }
  }
  dimnames(table) <- list(paste("AR",0:P,sep=""),paste("MA",0:Q,sep=""))
  table
}
l_saic_table <-saic_table(lcandy,4,5)
l_saic_table
```

```{r selected,echo=FALSE,warning=FALSE,message=FALSE,cache=TRUE}
fitsarima <- arima(dmcandy,order=c(0,0,3),seasonal = list(order=c(0,1,1),period=3))
fitsarima
```

## Compare and select  

### ARIMA model selected  

From the output above, we can see that ARIMA(0,1,1) model had a log-likelihood of 1119.05 which is greater than the SARIMA model.  

### Diagonis analysis  

From the ACF plot, we can see that the residual is quite stationary and from the QQplot, it indicates that the residual fitted normal distribution with light tails on both sides.  

```{r diagonis,echo=FALSE,warning=FALSE,message=FALSE,cache=TRUE}
fitarima = arima(dmcandy,order=c(0,1,1))
par(mfrow=c(1,2))
acf(fitarima$residuals)
qqnorm(fitarima$residuals)
qqline(fitarima$residuals)
```


# GARCH model

In this part, we will fit GARCH(1,1) model to our CPI dataset. And the output shows that the logliklihood is 1151.887 which is greater than the ARIMA(0,1,1) selected in part 2. This shows GARCH(1,1) model fits better than ARIMA(0,1,1) model on this CPI dataset.  

The GARCH(1,1) model used is shown below:  
$$
Y_n = \epsilon_n\sqrt{V_n}
$$
where  

$$
V_n = \alpha_0+\alpha_1Y_{n-1}^2 + \beta_1V_{n-1}
$$
and $\epsilon_{1:N}$ is white noise.  

```{r garch,echo=FALSE,warning=FALSE,message=FALSE,cache=TRUE}
require(tseries)
fitgarch <- garch(dmcandy,grad= "numerical",trace=FALSE)
L.garch <- tseries:::logLik.garch(fitgarch)
summary(fitgarch)
L.garch
```

The fitted GARCH model is:  
$$
Y_n = \epsilon_n\sqrt{V_n}
$$

where  

$$
V_n = 2.621\times10^{-5}+0.06Y_{n-1}^2 + 0.918V_{n-1}
$$

# POMP Model  

## Model description  

In this part, we will fit POMP model on CPI dataset. As production index is similar to price index, we will fit pomp model and compare the output with other model selected below.

### Financial leverage model  

In this part, the pomp model is from Breto(2014).  

$$
R_n = \frac{exp(2G_n)-1}{exp(2G_n)+1}
$$
where ${G_n}$ is the usual, Gaussian random walk.  

$$
Y_n = exp\{H_n/2\}\epsilon_n
$$

$$
H_n = \mu_h(1-\phi)+\phi H_{n-1} + \beta_{n-1}R_nexp\{-H_{n-1}/2\}+\omega_n
$$
$$
G_n = G_{n-1}+\upsilon_n
$$

where  
$$
\beta_n =Y_n\sigma_\eta\sqrt{1-\phi^2}
$$
$$
\epsilon_n ~is \ i .i.d \ N(0,1)
$$

$$
\upsilon_n ~is \ i .i.d \ N(0,{\sigma_\upsilon}^2)
$$

$$
\omega_n ~is \ i .i.d \ N(0,{\sigma_\omega}^2)
$$

```{r lib,echo=FALSE,warning=FALSE,message=FALSE,cache=TRUE}
set.seed(594709947L)
library(ggplot2)
library(tidyverse)
library(plyr)
library(reshape2)
library(foreach)
#library(doMC)
library(pomp)
stopifnot(packageVersion("pomp")>="2.0")
library(doParallel)
registerDoParallel()
library(doRNG)
registerDoRNG(34118892)
```

```{r set,,echo=FALSE,warning=FALSE,message=FALSE,cache=TRUE}
candy_statenames <- c("H","G","Y_state")
candy_rp_names <- c("sigma_nu","mu_h","phi","sigma_eta")
candy_ivp_names <- c("G_0","H_0")
candy_paramnames <- c(candy_rp_names,candy_ivp_names)


rproc1 <- "
  double beta,omega,nu;
  omega = rnorm(0, sigma_eta * sqrt( 1- phi*phi) * sqrt(1-tanh(G)*tanh(G)));
  nu = rnorm(0, sigma_nu);
  G += nu;
  beta = Y_state * sigma_eta * sqrt( 1 - phi*phi );
  H = mu_h*(1 - phi) +phi*H + beta * tanh(G) * exp(-H/2) + omega;
"

rproc2.sim <- "
  Y_state = rnorm(0, exp(H/2) );
"

rproc2.filt <- "
  Y_state = covaryt;
"

candy_rproc.sim <- paste(rproc1,rproc2.sim)
candy_rproc.filt <- paste(rproc1,rproc2.filt)

candy_rinit <- "
  G = G_0;
  H = H_0;
  Y_state = rnorm ( 0, exp(H/2) );
"

candy_rmeasure <- "
   y = Y_state;
"

candy_dmeasure <- "
   lik = dnorm(y,0,exp(H/2),give_log);
"

candy_partrans <- parameter_trans(
  log=c("sigma_eta","sigma_nu"),
  logit = "phi"
)
```


```{r filt,echo=FALSE,warning=FALSE,message=FALSE,cache=TRUE}
candy.filt <- pomp(data=data.frame(y=lcandy,time=1:length(lcandy)),
  statenames = candy_statenames,
  paramnames = candy_paramnames,
  times="time",
  t0=0,
  covar = covariate_table(
    time = 0:length(lcandy),
    covaryt=c(0,lcandy),
    times="time"),
  rmeasure = Csnippet(candy_rmeasure),
  dmeasure = Csnippet(candy_dmeasure),
  rprocess=discrete_time(step.fun = Csnippet(candy_rproc.filt),
    delta.t=1),
  rinit = Csnippet(candy_rinit),
  partrans = candy_partrans
)
```

```{r sim,echo=FALSE,warning=FALSE,message=FALSE,cache=TRUE}
params_test <- c(
  sigma_nu =exp(-5),
  mu_h = -0.25,
  phi = expit(4),
  sigma_eta = exp(-0.07),
  G_0 = 0,
  H_0 = 0
)

sim1.sim <- pomp(candy.filt,
  statenames = candy_statenames,
  paramnames = candy_paramnames,
  rprocess = discrete_time(
    step.fun = Csnippet(candy_rproc.sim),delta.t = 1)
)

sim1.sim <- simulate(sim1.sim,seed = 1,params = params_test)
```

```{r simfilt,echo=FALSE,warning=FALSE,message=FALSE,cache=TRUE}
sim1.filt <- pomp(sim1.sim, 
  covar=covariate_table(
    time=c(timezero(sim1.sim),time(sim1.sim)),
    covaryt=c(obs(sim1.sim),NA),
    times="time"),
  statenames=candy_statenames,
  paramnames=candy_paramnames,
  rprocess=discrete_time(
    step.fun=Csnippet(candy_rproc.filt),delta.t=1)
)
```

The runlevel of fitting the pomp model shown below:  

```{r runlevel,warning=FALSE,message=FALSE,cache=TRUE}
run_level <- 3
candy_Np <- switch(run_level,100,1e3,2e3)
candy_Nmif <- switch(run_level,10,100,200)
candy_Nreps_eval <- switch(run_level,4,10,20)
candy_Nreps_local <- switch(run_level,10,20,20)
candy_Nreps_global <- switch(run_level,10,20,100)
```

```{r para,echo=FALSE,warning=FALSE,message=FALSE}
library(doParallel)
registerDoParallel()
library(doRNG)
registerDoRNG(34118892)
```

The test of loglikelihood works well with efficient output and standard error.  

```{r pf,echo=FALSE,warning=FALSE,message=FALSE}
library(pomp)
stew(file=sprintf("pf1-%d.rda",run_level),{
  t.pf1 <- system.time(
    pf1 <- foreach(i=1:candy_Nreps_eval,
      .packages='pomp',.export = c("sim1.filt")) %dopar% pfilter(sim1.filt,Np=100))
},seed=493536993,kind="L'Ecuyer")
(L.pf1 <- logmeanexp(sapply(pf1,logLik),se=TRUE))
```

## Local search  

```{r mif2,echo=FALSE,warning=FALSE,message=FALSE}
candy_rw.sd_rp <- 0.02
candy_rw.sd_ivp <- 0.1
candy_cooling.fraction.50 <- 0.5
candy_rw.sd <- rw.sd(
  sigma_nu = candy_rw.sd_rp,
  mu_h = candy_rw.sd_rp,
  phi = candy_rw.sd_rp,
  sigma_eta = candy_rw.sd_rp,
  G_0 = ivp(candy_rw.sd_ivp),
  H_0 = ivp(candy_rw.sd_ivp)
)
```


```{r local,echo=FALSE,warning=FALSE,message=FALSE}
stew(file = sprintf("mif1-%d.rda",run_level),{
    t.if1 <- system.time({
  if1 <- foreach(i=1:candy_Nreps_local,
    .packages='pomp',.export = c("candy.filt","params_test","candy_Nmif","candy_Np","candy_rw.sd","candy_rw.sd_rp"),.combine=c) %dopar% mif2(candy.filt,
      params=params_test,
      Np=candy_Np,
      Nmif=candy_Nmif,
      cooling.fraction.50=candy_cooling.fraction.50,
      rw.sd = candy_rw.sd)
  L.if1 <- foreach(i=1:candy_Nreps_local,
    .packages='pomp',.export="candy_rw.sd_rp",.combine=rbind) %dopar% logmeanexp(
      replicate(candy_Nreps_eval, logLik(pfilter(candy.filt,
        params=coef(if1[[i]]),Np=candy_Np))), se=TRUE)
  })
},seed=318817883,kind="L'Ecuyer")

r.if1 <- data.frame(logLik=L.if1[,1],logLik_se=L.if1[,2],
  t(sapply(if1,coef)))
if (run_level>1) write.table(r.if1,file="candy_params.csv",
  append=TRUE,col.names=FALSE,row.names=FALSE)
```

```{r locpl,echo=FALSE,warning=FALSE,message=FALSE}
pairs(~logLik+sigma_nu+mu_h+phi+sigma_eta,
  data=subset(r.if1,logLik>max(logLik)-20))
summary(r.if1$logLik,digits=5)
```

The loglikelihood of local search is 1152. From the plot, it indicates that the range to get larger loglikelihood of each parameters.

## Global Search  

```{r box,echo=FALSE,warning=FALSE,message=FALSE}
candy_box <- rbind(
 sigma_nu=c(0.001,0.005),
 mu_h    =c(-1,0),
 phi = c(0.5,0.99),
 sigma_eta = c(0.5,1),
 G_0 = c(-2,2),
 H_0 = c(-1,1)
)
```

```{r boxev,echo=FALSE,warning=FALSE,message=FALSE}
stew(file=sprintf("box_eval-%d.rda",run_level),{
  t.box <- system.time({
    if.box <- foreach(i=1:candy_Nreps_global,
      .packages='pomp',.export = c("candy.filt","params_test","candy_Nmif","candy_Np","candy_rw.sd","candy_rw.sd_rp","candy_box","candy_rw.sd_rp"),.combine=c) %dopar% mif2(candy.filt,
      Np=candy_Np,
      Nmif=candy_Nmif,
      cooling.fraction.50=candy_cooling.fraction.50,
      rw.sd = candy_rw.sd,
        params=apply(candy_box,1,function(x)runif(1,x)))
    L.box <- foreach(i=1:candy_Nreps_global,
      .packages='pomp',.export="candy_rw.sd_rp",.combine=rbind) %dopar% {
         logmeanexp(replicate(candy_Nreps_eval, logLik(pfilter(
	     candy.filt,params=coef(if.box[[i]]),Np=candy_Np))), 
           se=TRUE)
       }
  })
},seed=290860873,kind="L'Ecuyer")

r.box <- data.frame(logLik=L.box[,1],logLik_se=L.box[,2],
  t(sapply(if.box,coef)))
if(run_level>1) write.table(r.box,file="candy_params.csv",
  append=TRUE,col.names=FALSE,row.names=FALSE)
summary(r.box$logLik,digits=5)
```

The loglikelihood of global search is 1159.  

```{r boxplot,echo=FALSE,warning=FALSE,message=FALSE}
pairs(~logLik+log(sigma_nu)+mu_h+phi+sigma_eta+H_0,
  data=subset(r.box,logLik>max(logLik)-10))
plot(if.box)
```

From the plot above, we can see that all the parameters almost converged after enough times of iteration.  

# Conclusion  

From the analysis above, we found that POMP model fits the best among the ARIMA&SARIMA, GARCH and POMP model with the largest log likelihood as 1159. And POMP model fits well as the runtime is quite low to converge.  

# Reference  
1. Candy Production dataset  
https://fred.stlouisfed.org/series/IPG3113S?utm_source=series_page&utm_medium=related_content&utm_term=other_formats&utm_campaign=other_format  
2. Class notes  
https://github.com/ionides/531w20  
3. Format of toc  
https://ionides.github.io/531w18/final_project/21/final.html 
4. Detrend  
https://ionides.github.io/531w18/final_project/27/final.html  
5. My midterm project  
https://ionides.github.io/531w20/midterm_project/1/Midterm-project.html
